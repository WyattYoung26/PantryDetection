{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtdQMH0AmABV"
      },
      "outputs": [],
      "source": [
        "#!pip install ultralytics\n",
        "#!pip install gTTS\n",
        "#!pip install pydub\n",
        "import cv2\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, display\n",
        "from pydub import AudioSegment\n",
        "\n",
        "\n",
        "\n",
        "folder_path = \"/bin/Food_p_Photos\"\n",
        "# Model\n",
        "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\")\n",
        "#model = torch.hub.load(\"ultralytics/yolov8\", \"yolov8l\")  # Replace \"yolov8s\" with other versions like \"yolov8m\" or \"yolov8l\" if needed\n",
        "\n",
        "\n",
        "#model = YOLO(\"yolo11n.pt\")\n",
        "\n",
        "# Images\n",
        "'''for f in \"zidane.jpg\", \"bus.jpg\":\n",
        "    #torch.hub.download_url_to_file(\"https://ultralytics.com/images/\" + f, f)  # download 2 images\n",
        "im1 = Image.open(\"zidane.jpg\")  # PIL image\n",
        "im2 = cv2.imread(\"bus.jpg\")[..., ::-1]  # OpenCV image (BGR to RGB)'''\n",
        "\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        if filename.endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\")):\n",
        "            img = Image.open(os.path.join(folder, filename))\n",
        "            images.append(img)\n",
        "    return images\n",
        "\n",
        "images = load_images_from_folder(folder_path)\n",
        "#print('These are the images',images)\n",
        "# Inference\n",
        "df_image = pd.DataFrame()\n",
        "df_counting=pd.DataFrame()\n",
        "df_cnt_temp=pd.DataFrame()\n",
        "#results = model(\"/bin/Food_p_Photos/fruit3.jpg\")  # batch of images\n",
        "i=0;\n",
        "\n",
        "for image in images:\n",
        "    i=i+1\n",
        "    results = model(image)\n",
        "    df_image=results.pandas().xyxy[0]  # im1 predictions (pandas)\n",
        "    df_image['name_tra'] = df_image['name']\n",
        "    df_image.loc[df_image['confidence'] <0.5, 'name_tra'] = 'unknown'\n",
        "    counts = df_image['name_tra'].value_counts()\n",
        "    df_cnt_temp=pd.DataFrame(counts)\n",
        "    df_cnt_temp.reset_index(inplace=True)\n",
        "    df_cnt_temp.columns.values[1] = 'Day ',i\n",
        "   #df_cnt_temp=df_cnt_temp.transpose()\n",
        "    if(i>1):\n",
        "        df_counting = pd.merge(df_counting, df_cnt_temp, on='name_tra', how='outer')\n",
        "    else:\n",
        "        df_counting=df_cnt_temp\n",
        "df_counting.fillna(0, inplace=True)\n",
        "print(df_counting)\n",
        "\n",
        "    #df_counting[('Day ',i)]=counts[:]\n",
        "\n",
        "textst='Today we have only'\n",
        "print(textst)\n",
        "testarr1=[]\n",
        "for row in range(len(df_cnt_temp)):\n",
        "    testarr1.append(str(df_cnt_temp.iloc[row, 1]))\n",
        "    testarr1.append(df_cnt_temp.iloc[row, 0])\n",
        "    print(df_cnt_temp.iloc[row, 1],' ',df_cnt_temp.iloc[row, 0])\n",
        "textst2='in the pantry'\n",
        "print(textst2)\n",
        "\n",
        "textst3='We are missing'\n",
        "print(textst3)\n",
        "testarr2=[]\n",
        "for row in range(len(df_counting)):\n",
        "    if(df_counting.iloc[row, (len(df_counting.columns)-1)]==0):\n",
        "        if(df_counting.iloc[row, 0]!='unknown'):\n",
        "            testarr2.append(df_counting.iloc[row, 0])\n",
        "            print(df_counting.iloc[row, 0])\n",
        "textst4='in the pantry'\n",
        "print(textst4)\n",
        "\n",
        "def generate_audio_segment(text, lang=\"en\"):\n",
        "    tts = gTTS(text=text, lang=lang)\n",
        "    tts.save(\"temp.mp3\")\n",
        "    return AudioSegment.from_file(\"temp.mp3\", format=\"mp3\")\n",
        "\n",
        "combined_audio = AudioSegment.empty()  # Start with an empty audio segment\n",
        "segment = generate_audio_segment(textst)\n",
        "combined_audio += segment\n",
        "for text in testarr1:\n",
        "    segment = generate_audio_segment(text)\n",
        "    combined_audio += segment  # Append the audio segment\n",
        "segment = generate_audio_segment(textst2)\n",
        "combined_audio += segment\n",
        "\n",
        "segment = generate_audio_segment(textst3)\n",
        "combined_audio += segment\n",
        "for text in testarr2:\n",
        "    segment = generate_audio_segment(text)\n",
        "    combined_audio += segment  # Append the audio segment\n",
        "segment = generate_audio_segment(textst4)\n",
        "combined_audio += segment\n",
        "# Export the combined audio to a single file\n",
        "combined_audio.export(\"combined_audio.mp3\", format=\"mp3\")\n",
        "\n",
        "#Playing the saved audio file\n",
        "display(Audio(\"combined_audio.mp3\", autoplay=True))\n"
      ]
    }
  ]
}